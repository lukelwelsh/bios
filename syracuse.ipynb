{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49b300a1-733b-4b62-8a00-f7e797b9a342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa217921-f9ac-40ed-8f2b-c91b9d083ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(range(2010, 2024))\n",
    "\n",
    "# URL structure for each university\n",
    "universities = {\n",
    "    \"Syracuse\": \"https://cuse.com/sports/football/roster\",\n",
    "    #add any universities you are interested in here\n",
    "}\n",
    "\n",
    "# Loop through each university\n",
    "for university_name, base_url in universities.items():\n",
    "    dataframes_by_year = []\n",
    "    #print(university_name)\n",
    "    #print(base_url)\n",
    "    # This will be our complete list of players across all years for current university\n",
    "    #all_players = []\n",
    "    \n",
    "    # Loop through each year\n",
    "    for year in years:\n",
    "        # Construct the URL for the year\n",
    "        if year == 2023:\n",
    "            url = base_url\n",
    "        else:\n",
    "            url = f\"{base_url}/{year}\"\n",
    "\n",
    "        page = requests.get(url)\n",
    "        players = BeautifulSoup(page.content, 'html.parser').find_all(class_ = \"s-person-details__detail-wrapper\")\n",
    "        #print(players)\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        attrs = soup.find_all(class_ = \"s-person-details__bio-stats-item\")\n",
    "        #print(attrs)\n",
    "        \n",
    "        extracted_attributes = []\n",
    "        \n",
    "        for attribute in attrs:\n",
    "            extracted_attributes.append(attribute.text)\n",
    "        #print(extracted_attributes)\n",
    "        \n",
    "        \n",
    "        hometowns = soup.find_all(class_ = \"s-person-card__content__person__location-item\")\n",
    "        \n",
    "        home_school = []\n",
    "        for hometown in hometowns:\n",
    "            #print(hometown.text)\n",
    "            home_school.append(hometown.text)\n",
    "        \n",
    "        all_players = []\n",
    "        i = 0\n",
    "        #all_players = []\n",
    "        for player in players:\n",
    "            player_info = {}\n",
    "            #print(extracted_attributes[i])\n",
    "            player_info[\"Name\"] = player.find(class_ = \"s-person-details__personal-single-line s-text-paragraph-bold flex items-center gap-2\").text\n",
    "            player_info[\"Position\"] = extracted_attributes[i][9:]\n",
    "            player_info[\"Academic Year\"] = extracted_attributes[i+1][14:]\n",
    "            player_info[\"Height\"] = extracted_attributes[i+2]\n",
    "            player_info[\"Weight\"] = extracted_attributes[i+3]    \n",
    "            all_players.append(player_info)\n",
    "        \n",
    "            i += 4 \n",
    "        \n",
    "        for i in range(0, len(home_school), 2):\n",
    "            hometown = home_school[i]\n",
    "            last_school = home_school[i + 1]\n",
    "            player_info = all_players[i // 2]\n",
    "            player_info[\"Hometown\"] = hometown[9:]\n",
    "            player_info[\"Last School\"] = last_school[12:]\n",
    "    \n",
    "        df = pd.DataFrame(all_players)\n",
    "\n",
    "        # Append the DataFrame to the list of DataFrames\n",
    "        dataframes_by_year.append(df)\n",
    "\n",
    "    # Save DataFrames for each year as separate CSV files\n",
    "    # Save DataFrames for each year as separate CSV files\n",
    "    for year, df in zip(years, dataframes_by_year):\n",
    "        file_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\", \"Syracuse\", \"Syracuse_Football\", \n",
    "                                 f'{university_name}_{year}_football_players.csv')\n",
    "        df.to_csv(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151c74ae-9452-44fd-9d20-faf9ecd9253c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a913472b-891a-42f5-aa42-dbf87a41e952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://cuse.com/sports/mens-basketball/roster/2010-11\n",
      "Error: 404 Client Error: Not Found for url: https://cuse.com/sports/mens-basketball/roster/2010-11. Skipping year 2010-11\n",
      "https://cuse.com/sports/mens-basketball/roster/2011-12\n",
      "https://cuse.com/sports/mens-basketball/roster/2012-13\n",
      "https://cuse.com/sports/mens-basketball/roster/2013-14\n",
      "https://cuse.com/sports/mens-basketball/roster/2014-15\n",
      "https://cuse.com/sports/mens-basketball/roster/2015-16\n",
      "https://cuse.com/sports/mens-basketball/roster/2016-17\n",
      "https://cuse.com/sports/mens-basketball/roster/2017-18\n",
      "https://cuse.com/sports/mens-basketball/roster/2018-19\n",
      "https://cuse.com/sports/mens-basketball/roster/2019-20\n",
      "https://cuse.com/sports/mens-basketball/roster/2020-21\n",
      "https://cuse.com/sports/mens-basketball/roster/2021-22\n",
      "https://cuse.com/sports/mens-basketball/roster/2022-23\n",
      "https://cuse.com/sports/mens-basketball/roster/2023-24\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "years = list(range(2010, 2024))\n",
    "\n",
    "# URL structure for each university\n",
    "universities = {\n",
    "    \"Syracuse\": \"https://cuse.com/sports/mens-basketball/roster\",\n",
    "    # Add any other universities you are interested in here\n",
    "}\n",
    "\n",
    "dataframes_by_year = []  # Define the list for DataFrames\n",
    "\n",
    "# Loop through each university\n",
    "for university_name, base_url in universities.items():\n",
    "    # Loop through each year\n",
    "    for year in years:\n",
    "        year1 = int(str(year)[-2:]) + 1\n",
    "        url = f\"{base_url}/{year}-{year1}\"\n",
    "        print(url)\n",
    "\n",
    "        try:\n",
    "            page = requests.get(url)\n",
    "            page.raise_for_status()  # Raise an error if the request is not successful\n",
    "\n",
    "            players = BeautifulSoup(page.content, 'html.parser').find_all(class_=\"s-person-details__detail-wrapper\")\n",
    "\n",
    "            response = requests.get(url)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "                attrs = soup.find_all(class_=\"s-person-details__bio-stats-item\")\n",
    "                extracted_attributes = []\n",
    "\n",
    "                for attribute in attrs:\n",
    "                    extracted_attributes.append(attribute.text)\n",
    "\n",
    "                hometowns = soup.find_all(class_=\"s-person-card__content__person__location-item\")\n",
    "                home_school = []\n",
    "\n",
    "                for hometown in hometowns:\n",
    "                    home_school.append(hometown.text)\n",
    "\n",
    "                all_players = []\n",
    "                i = 0\n",
    "                for player in players:\n",
    "                    player_info = {}\n",
    "                    player_info[\"Name\"] = player.find(class_=\"s-person-details__personal-single-line s-text-paragraph-bold flex items-center gap-2\").text\n",
    "                    player_info[\"Position\"] = extracted_attributes[i][9:]\n",
    "                    player_info[\"Academic Year\"] = extracted_attributes[i + 1][14:]\n",
    "                    player_info[\"Height\"] = extracted_attributes[i + 2]\n",
    "                    player_info[\"Weight\"] = extracted_attributes[i + 3]\n",
    "                    all_players.append(player_info)\n",
    "                    i += 4\n",
    "\n",
    "                for i in range(0, len(home_school), 2):\n",
    "                    hometown = home_school[i]\n",
    "                    last_school = home_school[i + 1]\n",
    "                    player_info = all_players[i // 2]\n",
    "                    player_info[\"Hometown\"] = hometown[9:]\n",
    "                    player_info[\"Last School\"] = last_school[12:]\n",
    "\n",
    "                # Create a DataFrame for the current year\n",
    "                df = pd.DataFrame(all_players)\n",
    "                dataframes_by_year.append(df)\n",
    "\n",
    "            else:\n",
    "                # Page doesn't exist for this year, so return a blank DataFrame\n",
    "                print(f\"Roster for {year}-{year1} does not exist. Returning blank DataFrame.\")\n",
    "                dataframes_by_year.append(pd.DataFrame())\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            # Handle network or connection errors\n",
    "            print(f\"Error: {e}. Skipping year {year}-{year1}\")\n",
    "            dataframes_by_year.append(pd.DataFrame())\n",
    "\n",
    "# Save DataFrames for each year as separate CSV files\n",
    "for year, df in zip(years, dataframes_by_year):\n",
    "        file_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\", \"Syracuse\", \"Syracuse_Mens_Basketball\",\n",
    "                                 f'{university_name}_{year}_Basketball_players.csv')\n",
    "        df.to_csv(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4af50c0-3365-47d3-a5ed-c2a44dd67334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
